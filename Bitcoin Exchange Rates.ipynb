{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bitcoin Exchange Rates\n",
    "\n",
    "## final project for DSCI 6007\n",
    "\n",
    "Charles Franzen\n",
    "\n",
    "### Project Overview\n",
    "\n",
    "#### Data Source\n",
    "\n",
    "The data come from a REST api that provides bitcoin exchange rates in a variety of currency, updated every minute.\n",
    "\n",
    "#### Project Goals\n",
    "\n",
    "1) Gather data: Pull data continously from an api.\n",
    "\n",
    "2) Data persistence: Keep all the data I gather\n",
    "\n",
    "3) Data structuring: Transform data into 3NF for more efficient querying\n",
    "\n",
    "4) Batch processing: Perform batch operations using a distributed system\n",
    "\n",
    "5) Stream processing: Do real-time analysis on data as it comes in\n",
    "\n",
    "6) Front end: Have a webserver that provides easy access to the results of the analysis.\n",
    "\n",
    "#### DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: dataflow Pages: 1 -->\n",
       "<svg width=\"257pt\" height=\"790pt\"\n",
       " viewBox=\"0.00 0.00 257.43 789.58\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 785.5755)\">\n",
       "<title>dataflow</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-785.5755 253.4324,-785.5755 253.4324,4 -4,4\"/>\n",
       "<!-- I -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>I</title>\n",
       "<text text-anchor=\"middle\" x=\"170.115\" y=\"-766.3755\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">BitCoin</text>\n",
       "<text text-anchor=\"middle\" x=\"170.115\" y=\"-752.3755\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">REST API</text>\n",
       "</g>\n",
       "<!-- R -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>R</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"200.9911,-708.5755 139.2389,-708.5755 139.2389,-672.5755 200.9911,-672.5755 200.9911,-708.5755\"/>\n",
       "<text text-anchor=\"middle\" x=\"170.115\" y=\"-693.3755\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">HTTP</text>\n",
       "<text text-anchor=\"middle\" x=\"170.115\" y=\"-679.3755\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">requests</text>\n",
       "</g>\n",
       "<!-- I&#45;&gt;R -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>I&#45;&gt;R</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M170.115,-745.5306C170.115,-737.4583 170.115,-727.7519 170.115,-718.7572\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"173.6151,-718.6658 170.115,-708.6659 166.6151,-718.6659 173.6151,-718.6658\"/>\n",
       "</g>\n",
       "<!-- DL -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>DL</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"161.3295,-608.5755 158.3295,-612.5755 137.3295,-612.5755 134.3295,-608.5755 100.9005,-608.5755 100.9005,-572.5755 161.3295,-572.5755 161.3295,-608.5755\"/>\n",
       "<text text-anchor=\"middle\" x=\"131.115\" y=\"-593.3755\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">S3 Data</text>\n",
       "<text text-anchor=\"middle\" x=\"131.115\" y=\"-579.3755\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Lake</text>\n",
       "</g>\n",
       "<!-- R&#45;&gt;DL -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>R&#45;&gt;DL</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M149.9012,-672.3799C145.2106,-667.104 140.7596,-661.0146 137.9011,-654.5755 132.9723,-643.4728 131.0059,-630.2576 130.3748,-618.7266\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"133.8735,-618.6284 130.1238,-608.7194 126.8757,-618.804 133.8735,-618.6284\"/>\n",
       "<text text-anchor=\"middle\" x=\"162.2219\" y=\"-643.3755\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Kinesis</text>\n",
       "<text text-anchor=\"middle\" x=\"162.2219\" y=\"-629.3755\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Firehose</text>\n",
       "</g>\n",
       "<!-- S -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>S</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"247.2779,-554.5755 170.9522,-554.5755 170.9522,-518.5755 247.2779,-518.5755 247.2779,-554.5755\"/>\n",
       "<text text-anchor=\"middle\" x=\"209.115\" y=\"-539.3755\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Stream</text>\n",
       "<text text-anchor=\"middle\" x=\"209.115\" y=\"-525.3755\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Processing</text>\n",
       "</g>\n",
       "<!-- R&#45;&gt;S -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>R&#45;&gt;S</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M179.0719,-672.5707C181.6248,-666.914 184.2233,-660.5767 186.115,-654.5755 195.5711,-624.5772 201.8644,-589.0064 205.4418,-564.8191\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"208.9118,-565.2769 206.8529,-554.8841 201.9813,-564.2925 208.9118,-565.2769\"/>\n",
       "<text text-anchor=\"middle\" x=\"216.6668\" y=\"-643.3755\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Kinesis</text>\n",
       "<text text-anchor=\"middle\" x=\"216.6668\" y=\"-629.3755\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Streams</text>\n",
       "</g>\n",
       "<!-- CL -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>CL</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"183.2906,-471.1816 143.7028,-500.4698 64.5272,-500.4698 24.9394,-471.1816 64.5272,-441.8935 143.7028,-441.8935 183.2906,-471.1816\"/>\n",
       "<text text-anchor=\"middle\" x=\"104.115\" y=\"-473.9816\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Normalization</text>\n",
       "<text text-anchor=\"middle\" x=\"104.115\" y=\"-459.9816\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Cluster</text>\n",
       "</g>\n",
       "<!-- DL&#45;&gt;CL -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>DL&#45;&gt;CL</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M127.0143,-572.4421C123.3124,-556.0724 117.7385,-531.4248 113.0169,-510.5458\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"116.399,-509.6333 110.7794,-500.6516 109.5714,-511.1774 116.399,-509.6333\"/>\n",
       "<text text-anchor=\"middle\" x=\"134.7737\" y=\"-539.3755\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">raw</text>\n",
       "<text text-anchor=\"middle\" x=\"134.7737\" y=\"-525.3755\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">data</text>\n",
       "</g>\n",
       "<!-- S3 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>S3</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"187.4531,-182 184.4531,-186 163.4531,-186 160.4531,-182 116.7769,-182 116.7769,-146 187.4531,-146 187.4531,-182\"/>\n",
       "<text text-anchor=\"middle\" x=\"152.115\" y=\"-166.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">S3 results</text>\n",
       "<text text-anchor=\"middle\" x=\"152.115\" y=\"-152.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">files</text>\n",
       "</g>\n",
       "<!-- S&#45;&gt;S3 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>S&#45;&gt;S3</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M209.8108,-518.5222C210.697,-493.9345 212.115,-448.5393 212.115,-409.7878 212.115,-409.7878 212.115,-409.7878 212.115,-275.3939 212.115,-243.2032 192.4532,-211.364 175.6403,-190.0227\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"178.1944,-187.6177 169.1481,-182.1027 172.7808,-192.0553 178.1944,-187.6177\"/>\n",
       "<text text-anchor=\"middle\" x=\"230.7737\" y=\"-362.5878\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">stream</text>\n",
       "<text text-anchor=\"middle\" x=\"230.7737\" y=\"-348.5878\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">results</text>\n",
       "</g>\n",
       "<!-- S2 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>S2</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"137.3811,-377.7878 134.3811,-381.7878 113.3811,-381.7878 110.3811,-377.7878 60.8489,-377.7878 60.8489,-341.7878 137.3811,-341.7878 137.3811,-377.7878\"/>\n",
       "<text text-anchor=\"middle\" x=\"99.115\" y=\"-362.5878\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">S3 parquet</text>\n",
       "<text text-anchor=\"middle\" x=\"99.115\" y=\"-348.5878\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">files</text>\n",
       "</g>\n",
       "<!-- CL&#45;&gt;S2 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>CL&#45;&gt;S2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M102.7882,-441.6226C102.043,-425.0204 101.118,-404.411 100.3826,-388.0282\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"103.8755,-387.7903 99.9306,-377.9573 96.8826,-388.1042 103.8755,-387.7903\"/>\n",
       "<text text-anchor=\"middle\" x=\"130.1048\" y=\"-412.5878\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">structured</text>\n",
       "<text text-anchor=\"middle\" x=\"130.1048\" y=\"-398.5878\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">data</text>\n",
       "</g>\n",
       "<!-- CL2 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>CL2</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"184.3452,-275.3939 138.2301,-304.682 45.9999,-304.682 -.1152,-275.3939 45.9999,-246.1057 138.2301,-246.1057 184.3452,-275.3939\"/>\n",
       "<text text-anchor=\"middle\" x=\"92.115\" y=\"-278.1939\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Batch Processing</text>\n",
       "<text text-anchor=\"middle\" x=\"92.115\" y=\"-264.1939\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(Spark)</text>\n",
       "</g>\n",
       "<!-- S2&#45;&gt;CL2 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>S2&#45;&gt;CL2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M97.5961,-341.4755C96.9534,-333.7266 96.1777,-324.3753 95.4148,-315.1774\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"98.8814,-314.6279 94.5666,-304.9515 91.9053,-315.2066 98.8814,-314.6279\"/>\n",
       "</g>\n",
       "<!-- CL2&#45;&gt;S3 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>CL2&#45;&gt;S3</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M108.0364,-245.8348C117.1491,-228.9164 128.5033,-207.8367 137.4056,-191.3089\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"140.6676,-192.6334 142.3284,-182.1695 134.5047,-189.3139 140.6676,-192.6334\"/>\n",
       "<text text-anchor=\"middle\" x=\"151.3909\" y=\"-216.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">batch</text>\n",
       "<text text-anchor=\"middle\" x=\"151.3909\" y=\"-202.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">results</text>\n",
       "</g>\n",
       "<!-- FE -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>FE</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"188.5057,-109 115.7243,-109 115.7243,-73 188.5057,-73 188.5057,-109\"/>\n",
       "<text text-anchor=\"middle\" x=\"152.115\" y=\"-93.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Front End</text>\n",
       "<text text-anchor=\"middle\" x=\"152.115\" y=\"-79.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Server</text>\n",
       "</g>\n",
       "<!-- S3&#45;&gt;FE -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>S3&#45;&gt;FE</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M152.115,-145.9551C152.115,-137.8828 152.115,-128.1764 152.115,-119.1817\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"155.6151,-119.0903 152.115,-109.0904 148.6151,-119.0904 155.6151,-119.0903\"/>\n",
       "</g>\n",
       "<!-- W -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>W</title>\n",
       "<text text-anchor=\"middle\" x=\"152.115\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">the web</text>\n",
       "</g>\n",
       "<!-- FE&#45;&gt;W -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>FE&#45;&gt;W</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M152.115,-72.9551C152.115,-64.8828 152.115,-55.1764 152.115,-46.1817\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"155.6151,-46.0903 152.115,-36.0904 148.6151,-46.0904 155.6151,-46.0903\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x109a13550>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import graphviz as gv\n",
    "\n",
    "g = gv.Source('''\n",
    "digraph dataflow {\n",
    "    I [label=\"BitCoin\\nREST API\", shape=\"plaintext\"];\n",
    "    R [label=\"HTTP\\nrequests\", shape=\"box\"];\n",
    "    DL [label=\"S3 Data\\nLake\", shape=\"folder\"];\n",
    "    S [label=\"Stream\\nProcessing\", shape=\"box\"];\n",
    "    CL [label=\"Normalization\\nCluster\", shape=\"hexagon\"];\n",
    "    S2 [label=\"S3 parquet\\nfiles\", shape=\"folder\"];\n",
    "    CL2 [label=\"Batch Processing\\n(Spark)\", shape=\"hexagon\"];\n",
    "    S3 [label=\"S3 results\\nfiles\", shape=\"folder\"];\n",
    "    FE [label=\"Front End\\nServer\", shape=\"box\"];\n",
    "    W [label=\"the web\", shape=\"plaintext\"];\n",
    "    \n",
    "    I -> R;\n",
    "    R -> DL [label=\"Kinesis\\nFirehose\"];\n",
    "    R -> S [label=\"Kinesis\\nStreams\"];\n",
    "    DL -> CL [label=\"raw\\ndata\"];\n",
    "    CL -> S2 [label=\"structured\\ndata\"];\n",
    "    S2 -> CL2;\n",
    "    CL2 -> S3 [label=\"batch\\nresults\"];\n",
    "    S -> S3 [label=\"stream\\nresults\"];\n",
    "    S3 -> FE;\n",
    "    FE -> W;\n",
    "    \n",
    "\n",
    "}''')\n",
    "\n",
    "g.save('dag.gv')\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Project Details\n",
    "\n",
    "##### Ingestion\n",
    "\n",
    "I used the requests library to make HTTP requests to the Bitcoin Price Index. I used an EC2 instance and routed records into a Kinesis Firehose and a Kinesis Stream.\n",
    "\n",
    "##### Storage\n",
    "\n",
    "The Firehose goes to an S3 bucket, where the raw data are stored\n",
    "\n",
    "##### Normalization\n",
    "\n",
    "An EMR instance normalizes the data every day, using Spark. Structured data are output as parquet files and stored on S3. If I had time, I would have liked to explore time-series optimized databases, like Riak TS.\n",
    "\n",
    "##### Batch Processing\n",
    "\n",
    "For batch processing, I computed mins, maxs, and means for different time frames. I also computed moving averages over windows of time.\n",
    "\n",
    "Originally I wanted to use batch processing to perfrom hyperparameter selection for my prediction model. This would have involved fitting a model to every 60-minute window in the dataset, for each set of parameters. Predictions would be compared with the true values, and RMSE used to evaluate relative model performance.\n",
    "\n",
    "I was able to use Spark's windowing functionality to compute rolling means and standard deviations, but as of now Pyspark does not support user defined aggregation functions. I wrote one anyways and tested it in Pandas, though I wasn't able to spend enough time on it to find a really good model. Once this feature is added to Spark, I'll be ready to take advantage.\n",
    "\n",
    "Results of batch processes were stored as pickled Pandas DataFrames.\n",
    "\n",
    "##### Stream Processing\n",
    "\n",
    "Since I only wanted to do stream processing on the latest hour of data, I just wrote a Stream consumer based on Pandas. It keeps a cache of the last 60 mins of data, fits a Gaussian Process Regressor, and makes 1, 5, and 10 minute projections.\n",
    "\n",
    "The results are stored on S3 as pickled Pandas DataFrames.\n",
    "\n",
    "##### Front End\n",
    "\n",
    "I used Spyre to create a three-page front end. One page shows min, max, and averages rates over hours and days. Another shows the last day and week of full data, along with a rolling average. The final page shows the projections and the latest data from the stream processor.\n",
    "\n",
    "#### Data System Considerations\n",
    "\n",
    "##### Robustness and tolerance\n",
    "\n",
    "S3 is very robust. If the stream goes down, short-term functionality will be lost on the front-end, but the data itself will be safe in S3. One point of concern is that the REST API will only be called on a single EC2 machine. An improvement would be to have a redundant http requester and S3 data lake, so that if a requester goes down there will be a backup.\n",
    "\n",
    "##### Low latency reads and updates.\n",
    "\n",
    "The Lambda architecture allows the low latency of stream processing to be supported by the robustness and fault-tolerance of S3 and distributed databases. Latency on batch processing will be high, but it's only used for long-term applications.\n",
    "\n",
    "##### Scalability\n",
    "\n",
    "Most of these technologies are fully scalable.\n",
    "\n",
    "As for horizontal scaling: EC2, S3, and Spark are all highly scalable, horizontally. Spyre is only dealing with relatively small 'views' of the data, so it will scale fine as the data grows. However, if the number of data sources and desired views increases too much, a more heavy-duty front-end will be necessary.\n",
    "\n",
    "The Kinesis consumer is not very scalable. If the volume of data grows dramatically, something like Flink or Spark Streaming will need to be implemented.\n",
    "\n",
    "Fitting Gaussian Processes on more of the data might be a bit of a problem. As the data get bigger in terms of the number of points in the time-series, this technique scales fairly well: predictions can be made by keeping a small number of training points with an exponentially increasing distance between them further back in history. An issue is increasing the number of features. Gaussian Random Fields are extremely powerful, but also very computationally intensive. Scikit-learns implementations are pretty fast.\n",
    "\n",
    "##### Generalization\n",
    "\n",
    "This architecture will be extremely general. There are many, *many* REST APIs, and many time series that would benefit from short-term stream processing and long-term batch processing. Galaxies of financial data come in this form.\n",
    "\n",
    "##### Extensibility\n",
    "\n",
    "This project is easily extensible. All of the systems in place support the addition of new data sources, features, and models.\n",
    "\n",
    "##### Ad hoc Queries\n",
    "\n",
    "Ad hoc queries are a bit iffy. Since the structured data are stored as parquet files, the whole database has to be loaded into Spark to do a query. Getting the data into a real database, NoSQL or RDBMS, should improve query performance.\n",
    "\n",
    "##### Minimal maintenance\n",
    "\n",
    "This system will have to be monitored, but there's not too much that will have to be maintained. There is the single point of failure in the HTTP requester, but the data stream is not of variable volume, so the Kinesis stream and everything downstream of that should be ok once the system is up and running. Cronjobs will take care of schedule data structuring and batch processing. The front end will update on refresh. \n",
    "\n",
    "The system is complex, especially considering how little data there will actually be in it, but it's built to scale and handle Big Data if and when it comes, so some complexity is necessary to handle those requirements.\n",
    "\n",
    "##### Debuggability\n",
    "\n",
    "The data will always be stored in raw form in S3, so bugs can be ferreted out, data restructured, and models recomputed if the worst happens and later layers get corrupted. I'll be doing my best to annotate code and provide guidance to those examining my system."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
